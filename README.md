# Case Oper

* Decidi utilizar Google Colab com integração do google drive para facilitar a execução do Spark, fora do ambiente do Databricks, já que não foi específicado em qual lugar deveria ser feito, decidi ir no mais prático.
* O notebook "first" tem as respostas para a primeira questão e possui o seguinte formato: ![image](https://github.com/andrebastosdata/case_oper/assets/173493147/a4a5dc21-9e46-41f5-ab93-76089437d52c)
* O notebook "second" tem as respostas para a segunda questão e possui o seguinte formato: ![image](https://github.com/andrebastosdata/case_oper/assets/173493147/585e89c8-7874-44ce-a090-496f6ce7f4e6)
* dentro da pasta "outputs" salvei alguns dataframes no formato parquet que foram utilizados para responder as questões.
* Escolhi usar o formato parquet para reduzir requisitos de armazenamento.


